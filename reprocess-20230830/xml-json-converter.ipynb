{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML to JSON conversion\n",
    "Goal: ease data processing, cope with weird output formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5, 11, 6, (5, 11), 23, '</PER>', '/', ((5, 11), (6, 7), (7, 10)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tag = re.compile(\"<(/?)(PER|ACT|LOC|CARDINAL|TITLE|FT|ENTRY)>\")\n",
    "test_str = \"sfsss</PER>dsfsf<ENTRY>\"\n",
    "m = next_tag.search(test_str)\n",
    "len(m.group(0)), m.start(0), m.end(0), m.end(0) - m.start(0), m.span(0), m.endpos, m.group(0), m.group(1), m.regs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, ('', 'ENTRY'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = next_tag.search(test_str, m.end(0))\n",
    "m.end(0), m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end',\n",
       " 'endpos',\n",
       " 'expand',\n",
       " 'group',\n",
       " 'groupdict',\n",
       " 'groups',\n",
       " 'lastgroup',\n",
       " 'lastindex',\n",
       " 'pos',\n",
       " 're',\n",
       " 'regs',\n",
       " 'span',\n",
       " 'start',\n",
       " 'string']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(m) if not x.startswith(\"__\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tag.search(\"sf\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_tag_scanner = re.compile(\"<(?P<closing>/?)(?P<tag>PER|ACT|LOC|CARDINAL|TITLE|FT|ENTRY)>\")\n",
    "def search_next_tag(string: str, start: int) -> tuple[str, bool, int]|None:\n",
    "    '''returns None or tag, startpos, endpos, is_closing'''\n",
    "    m = next_tag_scanner.search(string, start)\n",
    "    if m is None:\n",
    "        return None\n",
    "    return m.group(\"tag\"), m.start(0), m.end(0), m.group(\"closing\") == \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER True\n",
      "ENTRY False\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "while match := search_next_tag(test_str, pos):\n",
    "    tag, _startpos, endpos, closing = match\n",
    "    print(tag, closing)\n",
    "    pos = endpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State definitions\n",
    "STATE_EXPECT_OPENING_TAG, STATE_EXPECT_CLOSING_TAG = range(2)\n",
    "\n",
    "def xml_to_dict(xml_path: str) -> dict:\n",
    "\n",
    "    \"\"\"Parses a pseudo-XML file (list of tagged lines) to extract entries, copping with unpaired and missing tags.\n",
    "\n",
    "    It works by scanning the file line by line, looking for tags.\n",
    "    When an <ENTRY> or an </ENTRY> tag is found, the entry being parse is added to the list of entries, and any field being parsed is discarded.\n",
    "    When an opening tag like <PER>, <ACT> and so on is found, we start slurping text until another tag is found.\n",
    "    If the next tag is properly closing the one we just read, then we finish slurping the text before the new tag, add the field (tag, text) to the entry, and finally start waiting for a new opening tag.\n",
    "    If the next tag is incorrect, we discart the text and tag we started collecting, and wait for a new opening tag.\n",
    "    Some normalization and fixes should be performed before parsing each line (project to latin script, deal with easy mistakes like forgotten digits around a <CARDINAL>\\d+</CARDINAL> construct) but non is implemented yet.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: When some bug reveals itself…\n",
    "\n",
    "    Returns:\n",
    "        list[list[tuple[str,str]]]: list of entries. Entries are lists of tuple (tag name, value), like `[('PER', 'Cantagrel'), ('ACT', 'architecte')]`. This should ease splitting when required.\n",
    "    \"\"\"\n",
    "    all_entries: list[list[tuple[str,str]]] = []\n",
    "    current_entry: list[tuple[str,str]] = []\n",
    "    current_field_type: str|None = None\n",
    "    current_field_value: str = \"\"\n",
    "\n",
    "    # Helper fonctions, capturing variables from main function context\n",
    "    def _reinit_field(tag: str|None):\n",
    "        nonlocal current_field_type\n",
    "        nonlocal current_field_value\n",
    "        current_field_type = tag\n",
    "        current_field_value = \"\"\n",
    "    \n",
    "    def _commit_entry():\n",
    "        nonlocal all_entries\n",
    "        nonlocal current_entry\n",
    "        # Must commit field before committing entry\n",
    "        _reinit_field(None)\n",
    "        if current_entry:\n",
    "            all_entries.append(current_entry)\n",
    "        current_entry = []\n",
    "    \n",
    "    def _commit_field():\n",
    "        nonlocal current_field_type\n",
    "        nonlocal current_field_value\n",
    "        if current_field_type is None:\n",
    "            raise RuntimeError(\"Must not commit field with unknown type\")\n",
    "        current_entry.append((current_field_type, current_field_value))\n",
    "        _reinit_field(None)\n",
    "\n",
    "    def _append_to_field_value(string: str):\n",
    "        nonlocal current_field_type\n",
    "        nonlocal current_field_value\n",
    "        string_ = string.rstrip()\n",
    "        if len(current_field_value) > 0 and not current_field_value.endswith(\"-\"):\n",
    "            current_field_value += \" \"\n",
    "        current_field_value += string_\n",
    "\n",
    "    # main loop\n",
    "    state = STATE_EXPECT_OPENING_TAG\n",
    "    with open(xml_path, encoding=\"utf-8\") as xml_file:\n",
    "        for line in xml_file:\n",
    "            line_parsed = False\n",
    "            start_pos = 0\n",
    "\n",
    "            while not line_parsed:\n",
    "                # TODO rewrite the string: \n",
    "                # - project to latin (char-level fast substitution, see DAS22 code)\n",
    "                # - renormalize \"(\\d)*<CARDINAL>(\\d)+</CARDINAL>(\\d)*\" into \"<CARDINAL>\\1\\2\\3</CARDINAL>\"\n",
    "                match = search_next_tag(line, start_pos)\n",
    "                if not match:\n",
    "                    # No tag until end of line, store text (could be limited to STATE_EXPECT_CLOSING_TAG)\n",
    "                    _append_to_field_value(line[start_pos:])\n",
    "                    line_parsed = True\n",
    "                    continue\n",
    "                # else: we found a tag\n",
    "                tag_name, tag_start_pos, tag_end_pos, tag_is_closing = match\n",
    "                prev_start_pos = start_pos\n",
    "                # let us update the loop variable now to avoid mistakes\n",
    "                # In all cases, continue search after current tag\n",
    "                start_pos = tag_end_pos\n",
    "\n",
    "                # No matter which state we are in, we flush each time we get an ENTRY tag, opening or closing (until better results)\n",
    "                if tag_name == \"ENTRY\":\n",
    "                    # committing entry without previous field commit drops current field (which has unpaired tags or is noise)\n",
    "                    _commit_entry()\n",
    "                    continue\n",
    "\n",
    "                if state == STATE_EXPECT_OPENING_TAG:\n",
    "                    if tag_is_closing: \n",
    "                        # unexpected closing tag\n",
    "                        # drop current field\n",
    "                        # TODO should be logged to detect code problem in NER output generation\n",
    "                        _reinit_field(None)\n",
    "                        # state = STATE_EXPECT_OPENING_TAG  # already set\n",
    "                        # continue\n",
    "                    else:\n",
    "                        # we have a proper, non-ENTRY opening tag\n",
    "                        _reinit_field(tag_name)\n",
    "                        state = STATE_EXPECT_CLOSING_TAG\n",
    "                        # continue\n",
    "                    \n",
    "                elif state == STATE_EXPECT_CLOSING_TAG:\n",
    "                    if not tag_is_closing or tag_name != current_field_type:\n",
    "                        # unexpected opening tag and/or unpaired tag, drop field and expect new opening tag\n",
    "                        # TODO should be logged to detect code problem in NER output generation\n",
    "                        _reinit_field(None)\n",
    "                        state = STATE_EXPECT_OPENING_TAG\n",
    "                        # continue\n",
    "                    else:\n",
    "                        # we have a matching closing tag, add it to entry\n",
    "                        # don't forget to gather remaining chars between previous starting point and start of tag\n",
    "                        _append_to_field_value(line[prev_start_pos:tag_start_pos])\n",
    "                        _commit_field()\n",
    "                        state = STATE_EXPECT_OPENING_TAG\n",
    "\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Unknown state value: {state}\")\n",
    "    \n",
    "    return all_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('PER', 'Sédillot'), ('ACT', 'negociant')],\n",
       " [('PER', 'Halphen (Germ.'), ('ACT', 'juge au tribunal de commerce')],\n",
       " [('PER', 'Larrouy et Baillieux'), ('ACT', 'commissionnaires')],\n",
       " [('PER', 'Paccard (B.), Dufour et Cie'), ('ACT', 'banquiers')],\n",
       " [('PER', 'Bailleux, de la maison Larroux et Baillieux')],\n",
       " [('PER', 'Cazenave (Alphée)'), ('ACT', 'mě-decin')],\n",
       " [('PER', 'Cantagrel'), ('ACT', 'architecte')],\n",
       " [('PER', 'de Clansayes'),\n",
       "  ('ACT', 'něgociant'),\n",
       "  ('LOC', 'cité Tré-vise'),\n",
       "  ('CARDINAL', '6')],\n",
       " [('PER', 'Allegri (B.) et comp.'),\n",
       "  ('ACT', 'né-gociants'),\n",
       "  ('ACT', 'banquicrs')],\n",
       " [('PER', 'Gaillard (I.) et Cie NC'), ('ACT', 'commiss. en sucre intiq')]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_to_dict(\"output-sample/Didot_1853b-3:85-SAMPLE.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
